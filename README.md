The summary and the relevant blog post for this project can be found [here](https://medium.com/p/predicting-forest-cover-types-with-the-machine-learning-workflow-1f6f049bf4df?source=email-287e9909d3b5--writer.postDistributed&sk=d740915895b002b7424703d60a80d2f3)

This notebook aims to classify 7 different types of trees and give some clues about where to find them. I built an extra random forest classifier to detect fantastic trees in he Roosevelt National Forest of northern Colorado. I was able to classify the test set consisting 500.000 rows with 78% acuracy, placing this kernel among 28% among all competitors.

The notebook will follow the workflow suggested by Will Koehrsen in this [article](https://towardsdatascience.com/a-complete-machine-learning-walk-through-in-python-part-one-c62152f39420).

1) Undserstand, Clean and Format Data

2) Exploratory Data Analysis

3) Feature Engineering & Selection

4) Compare Several Machine Learning Models

5) Perform Hyperparameter Tuning on the Best Model

6) Evaluate the Best Model with Test Data

7) Interpret Model Results

8) Summary & Conclusions

Original kaggle kernel is [here](https://www.kaggle.com/cereniyim/fantastic-trees-where-to-find-how-to-detect-them).

It is one big notebook, for the summary and results you can move directly to the 8. Summary & Conclusions but I cannot gurantee that you are not going to miss some beautiful visualizations and interesting insights about data science and machine learning. Enjoy Reading!
